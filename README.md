# Vanna Ai Local

- **Run services**:

```sh
docker compose exec -it ollama-llm /bin/sh
```

- **Pull LLM model**:

```sh
ollama pull mistral
```

- **Run LLM model**:

```sh
ollama run mistral
```

- [vanna.ai](https://vanna.ai/docs/sqlite-ollama-chromadb/)
